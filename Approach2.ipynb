{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import glob \n",
    "import nrrd\n",
    "import shutil\n",
    "import json\n",
    "import h5py \n",
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage import zoom\n",
    "from datetime import datetime\n",
    "\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, Callback, ReduceLROnPlateau, LearningRateScheduler, EarlyStopping, TensorBoard\n",
    "from tensorflow.keras.callbacks import LambdaCallback, CSVLogger\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "import tensorflow as tf\n",
    "import util\n",
    "\n",
    "## for tensorboard\n",
    "# %load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/home/tester/jianhoong/jh_fyp_work/ct_scans_data/raw_data/'\n",
    "\n",
    "z_train = os.path.join(data_dir, 'training_data_z')\n",
    "z_train_image = os.path.join(z_train, 'training_images/training_images')\n",
    "z_train_mask = os.path.join(z_train, 'training_masks/training_masks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_nrrd_file(filepath):\n",
    "    '''read and load volume'''\n",
    "    pixelData, header = nrrd.read(filepath)\n",
    "    return pixelData\n",
    "\n",
    "def normalize(volume):\n",
    "    min = -1000 # min value of our data : -1000\n",
    "    max = 5000 # max value of our data : 5013\n",
    "    range = max - min\n",
    "    volume[volume < min] = min\n",
    "    volume[volume > max] = max\n",
    "    volume = (volume - min) / range\n",
    "    volume = volume.astype(\"float32\")\n",
    "    return volume\n",
    "\n",
    "def resize_volume(img):\n",
    "    '''resizing across z-axis'''\n",
    "    desired_depth = 128\n",
    "    desired_width = 256\n",
    "    desired_height = 256\n",
    "\n",
    "    current_depth = img.shape[-1]\n",
    "    current_width = img.shape[0]\n",
    "    current_height = img.shape[1]\n",
    "\n",
    "    depth_factor = 1 / (current_depth / desired_depth)\n",
    "    width_factor = 1 / (current_width / desired_width)\n",
    "    height_factor = 1/ (current_height / desired_height)\n",
    "    '''rotating image to fix orientation'''\n",
    "    img = ndimage.rotate(img, 90, reshape = False)\n",
    "    img = ndimage.zoom(img, (width_factor, height_factor, depth_factor), order = 1)\n",
    "    return img\n",
    "\n",
    "def process_scan(path):\n",
    "    volume = read_nrrd_file(path)\n",
    "    volume = normalize(volume)\n",
    "    volume = resize_volume(volume)\n",
    "    return volume\n",
    "\n",
    "def sorted_alnum(l):\n",
    "    convert = lambda text: int(text) if text.isdigit() else text \n",
    "    alphanum_key = lambda key : [convert(c) for c in re.split('([0-9]+)', key)]\n",
    "    return sorted(l, key = alphanum_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_5_dim = [1, 2, 7, 11, 17, 24, 25, 26, 27, 30, 32, 39, 40, 41, 42, 43, 45, 46, 50]\n",
    "test_5_dim = [2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = sorted_alnum([os.path.join(z_train_image, file) for file in os.listdir(z_train_image)  if int(re.findall(r'\\d+', file)[0]) in train_5_dim])\n",
    "train_mask_path = sorted_alnum([os.path.join(z_train_mask, file) for file in os.listdir(z_train_mask)  if int(re.findall(r'\\d+', file)[0]) in train_5_dim])\n",
    "\n",
    "test_path = sorted_alnum([os.path.join(z_train_image, file) for file in os.listdir(z_train_image)  if int(re.findall(r'\\d+', file)[0]) in test_5_dim])\n",
    "test_mask_path = sorted_alnum([os.path.join(z_train_mask, file) for file in os.listdir(z_train_mask)  if int(re.findall(r'\\d+', file)[0]) in test_5_dim])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, j in zip(train_path, train_mask_path):\n",
    "    print(i, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_generator(train_paths, mask_paths):\n",
    "    for scan_path, label_path in zip(train_paths, mask_paths):\n",
    "        scan_pixels = process_scan(scan_path)\n",
    "        mask_pixels = process_scan(label_path)\n",
    "        yield scan_pixels, mask_pixels\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume = process_scan(train_path[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume = tf.expand_dims(volume, axis = 0) ## 3 for channel last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = tf.data.Dataset.from_generator(training_generator, (tf.float32, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = train_loader.batch(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_loader.shuffle(len(train_path))\n",
    "train_dataset = train_dataset.apply(tf.data.experimental.ignore_errors())\n",
    "train_dataset = train_dataset.batch(2, drop_remainder=True).prefetch(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  tensorflow.keras import backend as K\n",
    "K.set_image_data_format('channels_first')\n",
    "\n",
    "model = util.unet_model_3d(loss_function=util.weighted_bce_dice_loss, metrics=[util.dice_coefficient])\n",
    "model.summary()\n",
    "plot_model(model, to_file='MyModel.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
